{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Wrangling Lab**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **45** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will perform data wrangling tasks to prepare raw data for analysis. Data wrangling involves cleaning, transforming, and organizing data into a structured format suitable for analysis. This lab focuses on tasks like identifying inconsistencies, encoding categorical variables, and feature transformation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completing this lab, you will be able to:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Identify and remove inconsistent data entries.\n",
    "\n",
    "- Encode categorical variables for analysis.\n",
    "\n",
    "- Handle missing values using multiple imputation strategies.\n",
    "\n",
    "- Apply feature scaling and transformation techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intsall the required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.12/site-packages (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Import the necessary module.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>1.1 Import necessary libraries and load the dataset.</h5>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure the dataset is loaded correctly by displaying the first few rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ResponseId                      MainBranch                 Age  \\\n",
      "0           1  I am a developer by profession  Under 18 years old   \n",
      "1           2  I am a developer by profession     35-44 years old   \n",
      "2           3  I am a developer by profession     45-54 years old   \n",
      "3           4           I am learning to code     18-24 years old   \n",
      "4           5  I am a developer by profession     18-24 years old   \n",
      "\n",
      "            Employment RemoteWork   Check  \\\n",
      "0  Employed, full-time     Remote  Apples   \n",
      "1  Employed, full-time     Remote  Apples   \n",
      "2  Employed, full-time     Remote  Apples   \n",
      "3   Student, full-time        NaN  Apples   \n",
      "4   Student, full-time        NaN  Apples   \n",
      "\n",
      "                                    CodingActivities  \\\n",
      "0                                              Hobby   \n",
      "1  Hobby;Contribute to open-source projects;Other...   \n",
      "2  Hobby;Contribute to open-source projects;Other...   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                             EdLevel  \\\n",
      "0                          Primary/elementary school   \n",
      "1       Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
      "2    Master’s degree (M.A., M.S., M.Eng., MBA, etc.)   \n",
      "3  Some college/university study without earning ...   \n",
      "4  Secondary school (e.g. American high school, G...   \n",
      "\n",
      "                                           LearnCode  \\\n",
      "0                             Books / Physical media   \n",
      "1  Books / Physical media;Colleague;On the job tr...   \n",
      "2  Books / Physical media;Colleague;On the job tr...   \n",
      "3  Other online resources (e.g., videos, blogs, f...   \n",
      "4  Other online resources (e.g., videos, blogs, f...   \n",
      "\n",
      "                                     LearnCodeOnline  ... JobSatPoints_6  \\\n",
      "0                                                NaN  ...            NaN   \n",
      "1  Technical documentation;Blogs;Books;Written Tu...  ...            0.0   \n",
      "2  Technical documentation;Blogs;Books;Written Tu...  ...            NaN   \n",
      "3  Stack Overflow;How-to videos;Interactive tutorial  ...            NaN   \n",
      "4  Technical documentation;Blogs;Written Tutorial...  ...            NaN   \n",
      "\n",
      "  JobSatPoints_7 JobSatPoints_8 JobSatPoints_9 JobSatPoints_10  \\\n",
      "0            NaN            NaN            NaN             NaN   \n",
      "1            0.0            0.0            0.0             0.0   \n",
      "2            NaN            NaN            NaN             NaN   \n",
      "3            NaN            NaN            NaN             NaN   \n",
      "4            NaN            NaN            NaN             NaN   \n",
      "\n",
      "  JobSatPoints_11           SurveyLength SurveyEase ConvertedCompYearly JobSat  \n",
      "0             NaN                    NaN        NaN                 NaN    NaN  \n",
      "1             0.0                    NaN        NaN                 NaN    NaN  \n",
      "2             NaN  Appropriate in length       Easy                 NaN    NaN  \n",
      "3             NaN               Too long       Easy                 NaN    NaN  \n",
      "4             NaN              Too short       Easy                 NaN    NaN  \n",
      "\n",
      "[5 rows x 114 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Stack Overflow survey data\n",
    "dataset_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\"\n",
    "df = pd.read_csv(dataset_url)\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Explore the Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>2.1 Summarize the dataset by displaying the column data types, counts, and missing values.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Summary:\n",
      "\n",
      "                    Data Type  Total Count  Non-Null Count  Missing Values\n",
      "ResponseId              int64        65437           65437               0\n",
      "MainBranch             object        65437           65437               0\n",
      "Age                    object        65437           65437               0\n",
      "Employment             object        65437           65437               0\n",
      "RemoteWork             object        65437           54806           10631\n",
      "...                       ...          ...             ...             ...\n",
      "JobSatPoints_11       float64        65437           29445           35992\n",
      "SurveyLength           object        65437           56182            9255\n",
      "SurveyEase             object        65437           56238            9199\n",
      "ConvertedCompYearly   float64        65437           23435           42002\n",
      "JobSat                float64        65437           29126           36311\n",
      "\n",
      "[114 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# --- Summarize dataset ---\n",
    "summary_df = pd.DataFrame({\n",
    "    \"Data Type\": df.dtypes,\n",
    "    \"Total Count\": len(df),\n",
    "    \"Non-Null Count\": df.notnull().sum(),\n",
    "    \"Missing Values\": df.isnull().sum()\n",
    "})\n",
    "\n",
    "print(\"Dataset Summary:\\n\")\n",
    "print(summary_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>2.2 Generate basic statistics for numerical columns.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponseId</th>\n",
       "      <th>CompTotal</th>\n",
       "      <th>WorkExp</th>\n",
       "      <th>JobSatPoints_1</th>\n",
       "      <th>JobSatPoints_4</th>\n",
       "      <th>JobSatPoints_5</th>\n",
       "      <th>JobSatPoints_6</th>\n",
       "      <th>JobSatPoints_7</th>\n",
       "      <th>JobSatPoints_8</th>\n",
       "      <th>JobSatPoints_9</th>\n",
       "      <th>JobSatPoints_10</th>\n",
       "      <th>JobSatPoints_11</th>\n",
       "      <th>ConvertedCompYearly</th>\n",
       "      <th>JobSat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>65437.000000</td>\n",
       "      <td>3.374000e+04</td>\n",
       "      <td>29658.000000</td>\n",
       "      <td>29324.000000</td>\n",
       "      <td>29393.000000</td>\n",
       "      <td>29411.000000</td>\n",
       "      <td>29450.000000</td>\n",
       "      <td>29448.00000</td>\n",
       "      <td>29456.000000</td>\n",
       "      <td>29456.000000</td>\n",
       "      <td>29450.000000</td>\n",
       "      <td>29445.000000</td>\n",
       "      <td>2.343500e+04</td>\n",
       "      <td>29126.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>32719.000000</td>\n",
       "      <td>2.963841e+145</td>\n",
       "      <td>11.466957</td>\n",
       "      <td>18.581094</td>\n",
       "      <td>7.522140</td>\n",
       "      <td>10.060857</td>\n",
       "      <td>24.343232</td>\n",
       "      <td>22.96522</td>\n",
       "      <td>20.278165</td>\n",
       "      <td>16.169432</td>\n",
       "      <td>10.955713</td>\n",
       "      <td>9.953948</td>\n",
       "      <td>8.615529e+04</td>\n",
       "      <td>6.935041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18890.179119</td>\n",
       "      <td>5.444117e+147</td>\n",
       "      <td>9.168709</td>\n",
       "      <td>25.966221</td>\n",
       "      <td>18.422661</td>\n",
       "      <td>21.833836</td>\n",
       "      <td>27.089360</td>\n",
       "      <td>27.01774</td>\n",
       "      <td>26.108110</td>\n",
       "      <td>24.845032</td>\n",
       "      <td>22.906263</td>\n",
       "      <td>21.775652</td>\n",
       "      <td>1.867570e+05</td>\n",
       "      <td>2.088259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16360.000000</td>\n",
       "      <td>6.000000e+04</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.271200e+04</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>32719.000000</td>\n",
       "      <td>1.100000e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.500000e+04</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>49078.000000</td>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.079715e+05</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>65437.000000</td>\n",
       "      <td>1.000000e+150</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.625660e+07</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ResponseId      CompTotal       WorkExp  JobSatPoints_1  \\\n",
       "count  65437.000000   3.374000e+04  29658.000000    29324.000000   \n",
       "mean   32719.000000  2.963841e+145     11.466957       18.581094   \n",
       "std    18890.179119  5.444117e+147      9.168709       25.966221   \n",
       "min        1.000000   0.000000e+00      0.000000        0.000000   \n",
       "25%    16360.000000   6.000000e+04      4.000000        0.000000   \n",
       "50%    32719.000000   1.100000e+05      9.000000       10.000000   \n",
       "75%    49078.000000   2.500000e+05     16.000000       22.000000   \n",
       "max    65437.000000  1.000000e+150     50.000000      100.000000   \n",
       "\n",
       "       JobSatPoints_4  JobSatPoints_5  JobSatPoints_6  JobSatPoints_7  \\\n",
       "count    29393.000000    29411.000000    29450.000000     29448.00000   \n",
       "mean         7.522140       10.060857       24.343232        22.96522   \n",
       "std         18.422661       21.833836       27.089360        27.01774   \n",
       "min          0.000000        0.000000        0.000000         0.00000   \n",
       "25%          0.000000        0.000000        0.000000         0.00000   \n",
       "50%          0.000000        0.000000       20.000000        15.00000   \n",
       "75%          5.000000       10.000000       30.000000        30.00000   \n",
       "max        100.000000      100.000000      100.000000       100.00000   \n",
       "\n",
       "       JobSatPoints_8  JobSatPoints_9  JobSatPoints_10  JobSatPoints_11  \\\n",
       "count    29456.000000    29456.000000     29450.000000     29445.000000   \n",
       "mean        20.278165       16.169432        10.955713         9.953948   \n",
       "std         26.108110       24.845032        22.906263        21.775652   \n",
       "min          0.000000        0.000000         0.000000         0.000000   \n",
       "25%          0.000000        0.000000         0.000000         0.000000   \n",
       "50%         10.000000        5.000000         0.000000         0.000000   \n",
       "75%         25.000000       20.000000        10.000000        10.000000   \n",
       "max        100.000000      100.000000       100.000000       100.000000   \n",
       "\n",
       "       ConvertedCompYearly        JobSat  \n",
       "count         2.343500e+04  29126.000000  \n",
       "mean          8.615529e+04      6.935041  \n",
       "std           1.867570e+05      2.088259  \n",
       "min           1.000000e+00      0.000000  \n",
       "25%           3.271200e+04      6.000000  \n",
       "50%           6.500000e+04      7.000000  \n",
       "75%           1.079715e+05      8.000000  \n",
       "max           1.625660e+07     10.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Identifying and Removing Inconsistencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>3.1 Identify inconsistent or irrelevant entries in specific columns (e.g., Country).</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'Country':\n",
      "['United States of America'\n",
      " 'United Kingdom of Great Britain and Northern Ireland' 'Canada' 'Norway'\n",
      " 'Uzbekistan' 'Serbia' 'Poland' 'Philippines' 'Bulgaria' 'Switzerland'\n",
      " 'India' 'Germany' 'Ireland' 'Italy' 'Ukraine' 'Australia' 'Brazil'\n",
      " 'Japan' 'Austria' 'Iran, Islamic Republic of...' 'France' 'Saudi Arabia'\n",
      " 'Romania' 'Turkey' 'Nepal' 'Algeria' 'Sweden' 'Netherlands' 'Croatia'\n",
      " 'Pakistan' 'Czech Republic' 'Republic of North Macedonia' 'Finland'\n",
      " 'Slovakia' 'Russian Federation' 'Greece' 'Israel' 'Belgium' 'Mexico'\n",
      " 'United Republic of Tanzania' 'Hungary' 'Argentina' 'Portugal'\n",
      " 'Sri Lanka' 'Latvia' 'China' 'Singapore' 'Lebanon' 'Spain' 'South Africa'\n",
      " 'Lithuania' 'Viet Nam' 'Dominican Republic' 'Indonesia' 'Kosovo'\n",
      " 'Morocco' 'Taiwan' 'Georgia' 'San Marino' 'Tunisia' 'Bangladesh'\n",
      " 'Nigeria' 'Liechtenstein' 'Denmark' 'Ecuador' 'Malaysia' 'Albania'\n",
      " 'Azerbaijan' 'Chile' 'Ghana' 'Peru' 'Bolivia' 'Egypt' 'Luxembourg'\n",
      " 'Montenegro' 'Cyprus' 'Paraguay' 'Kazakhstan' 'Slovenia' 'Jordan'\n",
      " 'Venezuela, Bolivarian Republic of...' 'Costa Rica' 'Jamaica' 'Thailand'\n",
      " 'Nicaragua' 'Myanmar' 'Republic of Korea' 'Rwanda'\n",
      " 'Bosnia and Herzegovina' 'Benin' 'El Salvador' 'Zimbabwe' 'Afghanistan'\n",
      " 'Estonia' 'Malta' 'Uruguay' 'Belarus' 'Colombia' 'Republic of Moldova'\n",
      " 'Isle of Man' 'Nomadic' 'New Zealand' 'Palestine' 'Armenia'\n",
      " 'United Arab Emirates' 'Maldives' 'Ethiopia' 'Fiji' 'Guatemala' 'Uganda'\n",
      " 'Turkmenistan' 'Mauritius' 'Kenya' 'Cuba' 'Gabon' 'Bahamas' 'South Korea'\n",
      " 'Iceland' 'Honduras' 'Hong Kong (S.A.R.)'\n",
      " \"Lao People's Democratic Republic\" 'Mongolia' 'Cambodia' 'Madagascar'\n",
      " 'Angola' 'Democratic Republic of the Congo' 'Syrian Arab Republic' 'Iraq'\n",
      " 'Namibia' 'Senegal' 'Kyrgyzstan' 'Zambia' 'Swaziland' \"Côte d'Ivoire\"\n",
      " 'Kuwait' 'Tajikistan' 'Burundi' 'Trinidad and Tobago' 'Mauritania'\n",
      " 'Sierra Leone' 'Panama' 'Somalia' 'North Korea' 'Dominica' 'Guyana'\n",
      " 'Togo' 'Oman' 'Barbados' 'Andorra'\n",
      " \"Democratic People's Republic of Korea\" 'Qatar' 'Sudan' 'Cameroon'\n",
      " 'Papua New Guinea' 'Bahrain' 'Yemen' 'Malawi' 'Burkina Faso'\n",
      " 'Congo, Republic of the...' 'Botswana' 'Guinea-Bissau' 'Mozambique'\n",
      " 'Central African Republic' 'Equatorial Guinea' 'Suriname' 'Belize'\n",
      " 'Libyan Arab Jamahiriya' 'Cape Verde' 'Brunei Darussalam' 'Bhutan'\n",
      " 'Guinea' 'Niger' 'Antigua and Barbuda' 'Mali' 'Samoa' 'Lesotho'\n",
      " 'Saint Kitts and Nevis' 'Monaco' 'Micronesia, Federated States of...'\n",
      " 'Haiti' nan 'Nauru' 'Liberia' 'Chad' 'Djibouti' 'Solomon Islands']\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Inspect unique values ---\n",
    "print(\"Unique values in 'Country':\")\n",
    "print(df[\"Country\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>3.2 Standardize entries in columns like Country or EdLevel by mapping inconsistent values to a consistent format.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Country values and counts:\n",
      "Country_lower\n",
      "united states of america                                11095\n",
      "NaN                                                      6507\n",
      "germany                                                  4947\n",
      "india                                                    4231\n",
      "united kingdom of great britain and northern ireland     3224\n",
      "                                                        ...  \n",
      "micronesia, federated states of...                          1\n",
      "nauru                                                       1\n",
      "chad                                                        1\n",
      "djibouti                                                    1\n",
      "solomon islands                                             1\n",
      "Name: count, Length: 186, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --- Step 2: Identify inconsistent / irrelevant entries ---\n",
    "# Detect case inconsistencies (e.g. \"USA\" vs \"Usa\")\n",
    "df[\"Country_lower\"] = df[\"Country\"].str.strip().str.lower()\n",
    "\n",
    "# Count normalized values\n",
    "country_counts = df[\"Country_lower\"].value_counts(dropna=False).sort_values(ascending=False)\n",
    "print(\"\\nCountry values and counts:\")\n",
    "print(country_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Encoding Categorical Variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>4.1 Encode the Employment column using one-hot encoding.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ResponseId                      MainBranch                 Age  \\\n",
      "0           1  I am a developer by profession  Under 18 years old   \n",
      "1           2  I am a developer by profession     35-44 years old   \n",
      "2           3  I am a developer by profession     45-54 years old   \n",
      "3           4           I am learning to code     18-24 years old   \n",
      "4           5  I am a developer by profession     18-24 years old   \n",
      "\n",
      "            Employment RemoteWork   Check  \\\n",
      "0  Employed, full-time     Remote  Apples   \n",
      "1  Employed, full-time     Remote  Apples   \n",
      "2  Employed, full-time     Remote  Apples   \n",
      "3   Student, full-time        NaN  Apples   \n",
      "4   Student, full-time        NaN  Apples   \n",
      "\n",
      "                                    CodingActivities  \\\n",
      "0                                              Hobby   \n",
      "1  Hobby;Contribute to open-source projects;Other...   \n",
      "2  Hobby;Contribute to open-source projects;Other...   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                             EdLevel  \\\n",
      "0                          Primary/elementary school   \n",
      "1       Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
      "2    Master’s degree (M.A., M.S., M.Eng., MBA, etc.)   \n",
      "3  Some college/university study without earning ...   \n",
      "4  Secondary school (e.g. American high school, G...   \n",
      "\n",
      "                                           LearnCode  \\\n",
      "0                             Books / Physical media   \n",
      "1  Books / Physical media;Colleague;On the job tr...   \n",
      "2  Books / Physical media;Colleague;On the job tr...   \n",
      "3  Other online resources (e.g., videos, blogs, f...   \n",
      "4  Other online resources (e.g., videos, blogs, f...   \n",
      "\n",
      "                                     LearnCodeOnline  ...  \\\n",
      "0                                                NaN  ...   \n",
      "1  Technical documentation;Blogs;Books;Written Tu...  ...   \n",
      "2  Technical documentation;Blogs;Books;Written Tu...  ...   \n",
      "3  Stack Overflow;How-to videos;Interactive tutorial  ...   \n",
      "4  Technical documentation;Blogs;Written Tutorial...  ...   \n",
      "\n",
      "  Employment_Student, full-time;Not employed, but looking for work;Not employed, and not looking for work;Student, part-time  \\\n",
      "0                                              False                                                                           \n",
      "1                                              False                                                                           \n",
      "2                                              False                                                                           \n",
      "3                                              False                                                                           \n",
      "4                                              False                                                                           \n",
      "\n",
      "  Employment_Student, full-time;Not employed, but looking for work;Retired  \\\n",
      "0                                              False                         \n",
      "1                                              False                         \n",
      "2                                              False                         \n",
      "3                                              False                         \n",
      "4                                              False                         \n",
      "\n",
      "  Employment_Student, full-time;Not employed, but looking for work;Student, part-time  \\\n",
      "0                                              False                                    \n",
      "1                                              False                                    \n",
      "2                                              False                                    \n",
      "3                                              False                                    \n",
      "4                                              False                                    \n",
      "\n",
      "  Employment_Student, full-time;Retired  \\\n",
      "0                                 False   \n",
      "1                                 False   \n",
      "2                                 False   \n",
      "3                                 False   \n",
      "4                                 False   \n",
      "\n",
      "  Employment_Student, full-time;Student, part-time  \\\n",
      "0                                            False   \n",
      "1                                            False   \n",
      "2                                            False   \n",
      "3                                            False   \n",
      "4                                            False   \n",
      "\n",
      "  Employment_Student, full-time;Student, part-time;Employed, part-time  \\\n",
      "0                                              False                     \n",
      "1                                              False                     \n",
      "2                                              False                     \n",
      "3                                              False                     \n",
      "4                                              False                     \n",
      "\n",
      "  Employment_Student, full-time;Student, part-time;Retired  \\\n",
      "0                                              False         \n",
      "1                                              False         \n",
      "2                                              False         \n",
      "3                                              False         \n",
      "4                                              False         \n",
      "\n",
      "  Employment_Student, part-time  \\\n",
      "0                         False   \n",
      "1                         False   \n",
      "2                         False   \n",
      "3                         False   \n",
      "4                         False   \n",
      "\n",
      "  Employment_Student, part-time;Employed, part-time  \\\n",
      "0                                             False   \n",
      "1                                             False   \n",
      "2                                             False   \n",
      "3                                             False   \n",
      "4                                             False   \n",
      "\n",
      "  Employment_Student, part-time;Retired  \n",
      "0                                 False  \n",
      "1                                 False  \n",
      "2                                 False  \n",
      "3                                 False  \n",
      "4                                 False  \n",
      "\n",
      "[5 rows x 225 columns]\n"
     ]
    }
   ],
   "source": [
    "# --- 1. One-hot encode the 'Employment' column ---\n",
    "employment_encoded = pd.get_dummies(df[\"Employment\"], prefix=\"Employment\")\n",
    "\n",
    "# --- 2. Combine encoded columns back with original DataFrame ---\n",
    "df_encoded = pd.concat([df, employment_encoded], axis=1)\n",
    "\n",
    "print(df_encoded.head())\n",
    "#df_encoded.to_csv(\"encoded_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Handling Missing Values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>5.1 Identify columns with the highest number of missing values.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with the highest number of missing values:\n",
      "\n",
      "AINextMuch less integrated    64289\n",
      "AINextLess integrated         63082\n",
      "AINextNo change               52939\n",
      "AINextMuch more integrated    51999\n",
      "EmbeddedAdmired               48704\n",
      "                              ...  \n",
      "YearsCode                      5568\n",
      "NEWSOSites                     5151\n",
      "LearnCode                      4949\n",
      "EdLevel                        4653\n",
      "AISelect                       4530\n",
      "Length: 110, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Count missing values per column ---\n",
    "missing_count = df.isnull().sum()\n",
    "\n",
    "# --- 2. Sort descending (highest missing values first) ---\n",
    "missing_sorted = missing_count.sort_values(ascending=False)\n",
    "\n",
    "# --- 3. Display only columns that actually have missing values ---\n",
    "missing_sorted = missing_sorted[missing_sorted > 0]\n",
    "\n",
    "print(\"Columns with the highest number of missing values:\\n\")\n",
    "print(missing_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>5.2 Impute missing values in numerical columns (e.g., `ConvertedCompYearly`) with the mean or median.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled missing values in 'CompTotal' with 110000.00\n",
      "Filled missing values in 'WorkExp' with 9.00\n",
      "Filled missing values in 'JobSatPoints_1' with 10.00\n",
      "Filled missing values in 'JobSatPoints_4' with 0.00\n",
      "Filled missing values in 'JobSatPoints_5' with 0.00\n",
      "Filled missing values in 'JobSatPoints_6' with 20.00\n",
      "Filled missing values in 'JobSatPoints_7' with 15.00\n",
      "Filled missing values in 'JobSatPoints_8' with 10.00\n",
      "Filled missing values in 'JobSatPoints_9' with 5.00\n",
      "Filled missing values in 'JobSatPoints_10' with 0.00\n",
      "Filled missing values in 'JobSatPoints_11' with 0.00\n",
      "Filled missing values in 'ConvertedCompYearly' with 65000.00\n",
      "Filled missing values in 'JobSat' with 7.00\n",
      "\n",
      "Missing values in numeric columns have been imputed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_434/1563579131.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(impute_value, inplace=True)\n",
      "/tmp/ipykernel_434/1563579131.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(impute_value, inplace=True)\n",
      "/tmp/ipykernel_434/1563579131.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(impute_value, inplace=True)\n",
      "/tmp/ipykernel_434/1563579131.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(impute_value, inplace=True)\n",
      "/tmp/ipykernel_434/1563579131.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(impute_value, inplace=True)\n",
      "/tmp/ipykernel_434/1563579131.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(impute_value, inplace=True)\n",
      "/tmp/ipykernel_434/1563579131.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(impute_value, inplace=True)\n",
      "/tmp/ipykernel_434/1563579131.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(impute_value, inplace=True)\n",
      "/tmp/ipykernel_434/1563579131.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(impute_value, inplace=True)\n",
      "/tmp/ipykernel_434/1563579131.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(impute_value, inplace=True)\n",
      "/tmp/ipykernel_434/1563579131.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(impute_value, inplace=True)\n",
      "/tmp/ipykernel_434/1563579131.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(impute_value, inplace=True)\n",
      "/tmp/ipykernel_434/1563579131.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(impute_value, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- 1. Identify numeric columns ---\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# --- 2. Impute missing values in numeric columns ---\n",
    "for col in numeric_cols:\n",
    "    if df[col].isnull().sum() > 0:  # only process columns with NaN\n",
    "        # Choose either mean or median:\n",
    "        impute_value = df[col].median()   # ← change to df[col].mean() if preferred\n",
    "        df[col].fillna(impute_value, inplace=True)\n",
    "        print(f\"Filled missing values in '{col}' with {impute_value:.2f}\")\n",
    "\n",
    "print(\"\\nMissing values in numeric columns have been imputed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>5.3 Impute missing values in categorical columns (e.g., `RemoteWork`) with the most frequent value.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_434/3900489729.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(most_frequent, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled missing values in 'RemoteWork' with most frequent value: 'Hybrid (some remote, some in-person)'\n",
      "Filled missing values in 'CodingActivities' with most frequent value: 'Hobby'\n",
      "Filled missing values in 'EdLevel' with most frequent value: 'Bachelor’s degree (B.A., B.S., B.Eng., etc.)'\n",
      "Filled missing values in 'LearnCode' with most frequent value: 'Other online resources (e.g., videos, blogs, forum, online community)'\n",
      "Filled missing values in 'LearnCodeOnline' with most frequent value: 'Technical documentation;Blogs;Written Tutorials;Stack Overflow'\n",
      "Filled missing values in 'TechDoc' with most frequent value: 'API document(s) and/or SDK document(s);User guides or README files found in the source repository;Traditional public search engine'\n",
      "Filled missing values in 'YearsCode' with most frequent value: '10'\n",
      "Filled missing values in 'YearsCodePro' with most frequent value: '2'\n",
      "Filled missing values in 'DevType' with most frequent value: 'Developer, full-stack'\n",
      "Filled missing values in 'OrgSize' with most frequent value: '20 to 99 employees'\n",
      "Filled missing values in 'PurchaseInfluence' with most frequent value: 'I have some influence'\n",
      "Filled missing values in 'BuyNewTool' with most frequent value: 'Start a free trial;Ask developers I know/work with;Visit developer communities like Stack Overflow'\n",
      "Filled missing values in 'BuildvsBuy' with most frequent value: 'Is ready-to-go but also customizable for growth and targeted use cases'\n",
      "Filled missing values in 'TechEndorse' with most frequent value: 'APIs;Customization;Reputation for quality and excellence'\n",
      "Filled missing values in 'Country' with most frequent value: 'United States of America'\n",
      "Filled missing values in 'Currency' with most frequent value: 'EUR European Euro'\n",
      "Filled missing values in 'LanguageHaveWorkedWith' with most frequent value: 'HTML/CSS;JavaScript;TypeScript'\n",
      "Filled missing values in 'LanguageWantToWorkWith' with most frequent value: 'Python'\n",
      "Filled missing values in 'LanguageAdmired' with most frequent value: 'Python'\n",
      "Filled missing values in 'DatabaseHaveWorkedWith' with most frequent value: 'PostgreSQL'\n",
      "Filled missing values in 'DatabaseWantToWorkWith' with most frequent value: 'PostgreSQL'\n",
      "Filled missing values in 'DatabaseAdmired' with most frequent value: 'PostgreSQL'\n",
      "Filled missing values in 'PlatformHaveWorkedWith' with most frequent value: 'Amazon Web Services (AWS)'\n",
      "Filled missing values in 'PlatformWantToWorkWith' with most frequent value: 'Amazon Web Services (AWS)'\n",
      "Filled missing values in 'PlatformAdmired' with most frequent value: 'Amazon Web Services (AWS)'\n",
      "Filled missing values in 'WebframeHaveWorkedWith' with most frequent value: 'React'\n",
      "Filled missing values in 'WebframeWantToWorkWith' with most frequent value: 'React'\n",
      "Filled missing values in 'WebframeAdmired' with most frequent value: 'React'\n",
      "Filled missing values in 'EmbeddedHaveWorkedWith' with most frequent value: 'Rasberry Pi'\n",
      "Filled missing values in 'EmbeddedWantToWorkWith' with most frequent value: 'Rasberry Pi'\n",
      "Filled missing values in 'EmbeddedAdmired' with most frequent value: 'Rasberry Pi'\n",
      "Filled missing values in 'MiscTechHaveWorkedWith' with most frequent value: '.NET (5+) '\n",
      "Filled missing values in 'MiscTechWantToWorkWith' with most frequent value: '.NET (5+) '\n",
      "Filled missing values in 'MiscTechAdmired' with most frequent value: '.NET (5+) '\n",
      "Filled missing values in 'ToolsTechHaveWorkedWith' with most frequent value: 'Docker'\n",
      "Filled missing values in 'ToolsTechWantToWorkWith' with most frequent value: 'Docker'\n",
      "Filled missing values in 'ToolsTechAdmired' with most frequent value: 'Docker'\n",
      "Filled missing values in 'NEWCollabToolsHaveWorkedWith' with most frequent value: 'Visual Studio Code'\n",
      "Filled missing values in 'NEWCollabToolsWantToWorkWith' with most frequent value: 'Visual Studio Code'\n",
      "Filled missing values in 'NEWCollabToolsAdmired' with most frequent value: 'Visual Studio Code'\n",
      "Filled missing values in 'OpSysPersonal use' with most frequent value: 'Windows'\n",
      "Filled missing values in 'OpSysProfessional use' with most frequent value: 'Windows'\n",
      "Filled missing values in 'OfficeStackAsyncHaveWorkedWith' with most frequent value: 'Jira'\n",
      "Filled missing values in 'OfficeStackAsyncWantToWorkWith' with most frequent value: 'Jira'\n",
      "Filled missing values in 'OfficeStackAsyncAdmired' with most frequent value: 'Jira'\n",
      "Filled missing values in 'OfficeStackSyncHaveWorkedWith' with most frequent value: 'Microsoft Teams'\n",
      "Filled missing values in 'OfficeStackSyncWantToWorkWith' with most frequent value: 'Microsoft Teams'\n",
      "Filled missing values in 'OfficeStackSyncAdmired' with most frequent value: 'Microsoft Teams'\n",
      "Filled missing values in 'AISearchDevHaveWorkedWith' with most frequent value: 'ChatGPT'\n",
      "Filled missing values in 'AISearchDevWantToWorkWith' with most frequent value: 'ChatGPT'\n",
      "Filled missing values in 'AISearchDevAdmired' with most frequent value: 'ChatGPT'\n",
      "Filled missing values in 'NEWSOSites' with most frequent value: 'Stack Overflow;Stack Exchange'\n",
      "Filled missing values in 'SOVisitFreq' with most frequent value: 'A few times per week'\n",
      "Filled missing values in 'SOAccount' with most frequent value: 'Yes'\n",
      "Filled missing values in 'SOPartFreq' with most frequent value: 'Less than once per month or monthly'\n",
      "Filled missing values in 'SOHow' with most frequent value: 'Quickly finding code solutions;Finding reliable guidance from community-vetted answers'\n",
      "Filled missing values in 'SOComm' with most frequent value: 'No, not really'\n",
      "Filled missing values in 'AISelect' with most frequent value: 'Yes'\n",
      "Filled missing values in 'AISent' with most frequent value: 'Favorable'\n",
      "Filled missing values in 'AIBen' with most frequent value: 'Increase productivity;Greater efficiency;Speed up learning'\n",
      "Filled missing values in 'AIAcc' with most frequent value: 'Somewhat trust'\n",
      "Filled missing values in 'AIComplex' with most frequent value: 'Good, but not great at handling complex tasks'\n",
      "Filled missing values in 'AIToolCurrently Using' with most frequent value: 'Writing code;Debugging and getting help;Search for answers'\n",
      "Filled missing values in 'AIToolInterested in Using' with most frequent value: 'Learning about a codebase'\n",
      "Filled missing values in 'AIToolNot interested in Using' with most frequent value: 'Project planning'\n",
      "Filled missing values in 'AINextMuch more integrated' with most frequent value: 'Search for answers'\n",
      "Filled missing values in 'AINextNo change' with most frequent value: 'Writing code'\n",
      "Filled missing values in 'AINextMore integrated' with most frequent value: 'Writing code'\n",
      "Filled missing values in 'AINextLess integrated' with most frequent value: 'Writing code'\n",
      "Filled missing values in 'AINextMuch less integrated' with most frequent value: 'Writing code'\n",
      "Filled missing values in 'AIThreat' with most frequent value: 'No'\n",
      "Filled missing values in 'AIEthics' with most frequent value: 'Circulating misinformation or disinformation;Missing or incorrect attribution for sources of data;Biased results that do not represent diverse viewpoints'\n",
      "Filled missing values in 'AIChallenges' with most frequent value: 'Don’t trust the output or answers;AI tools lack context of codebase,  internal architecture, and/or company knowledge'\n",
      "Filled missing values in 'TBranch' with most frequent value: 'Yes'\n",
      "Filled missing values in 'ICorPM' with most frequent value: 'Individual contributor'\n",
      "Filled missing values in 'Knowledge_1' with most frequent value: 'Agree'\n",
      "Filled missing values in 'Knowledge_2' with most frequent value: 'Agree'\n",
      "Filled missing values in 'Knowledge_3' with most frequent value: 'Agree'\n",
      "Filled missing values in 'Knowledge_4' with most frequent value: 'Agree'\n",
      "Filled missing values in 'Knowledge_5' with most frequent value: 'Agree'\n",
      "Filled missing values in 'Knowledge_6' with most frequent value: 'Agree'\n",
      "Filled missing values in 'Knowledge_7' with most frequent value: 'Agree'\n",
      "Filled missing values in 'Knowledge_8' with most frequent value: 'Agree'\n",
      "Filled missing values in 'Knowledge_9' with most frequent value: 'Agree'\n",
      "Filled missing values in 'Frequency_1' with most frequent value: '1-2 times a week'\n",
      "Filled missing values in 'Frequency_2' with most frequent value: '1-2 times a week'\n",
      "Filled missing values in 'Frequency_3' with most frequent value: '1-2 times a week'\n",
      "Filled missing values in 'TimeSearching' with most frequent value: '30-60 minutes a day'\n",
      "Filled missing values in 'TimeAnswering' with most frequent value: '15-30 minutes a day'\n",
      "Filled missing values in 'Frustration' with most frequent value: 'None of these'\n",
      "Filled missing values in 'ProfessionalTech' with most frequent value: 'None of these'\n",
      "Filled missing values in 'ProfessionalCloud' with most frequent value: 'Hybrid (on-prem and cloud)'\n",
      "Filled missing values in 'ProfessionalQuestion' with most frequent value: 'Traditional public search engine'\n",
      "Filled missing values in 'Industry' with most frequent value: 'Software Development'\n",
      "Filled missing values in 'SurveyLength' with most frequent value: 'Appropriate in length'\n",
      "Filled missing values in 'SurveyEase' with most frequent value: 'Easy'\n",
      "Filled missing values in 'Country_lower' with most frequent value: 'united states of america'\n",
      "\n",
      "Missing values in categorical columns have been imputed.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Identify categorical (object or string) columns ---\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# --- 2. Impute missing values with the most frequent (mode) value ---\n",
    "for col in categorical_cols:\n",
    "    if df[col].isnull().sum() > 0:  # only handle columns with NaN\n",
    "        most_frequent = df[col].mode()[0]\n",
    "        df[col].fillna(most_frequent, inplace=True)\n",
    "        print(f\"Filled missing values in '{col}' with most frequent value: '{most_frequent}'\")\n",
    "\n",
    "print(\"\\nMissing values in categorical columns have been imputed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Feature Scaling and Transformation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>6.1 Apply Min-Max Scaling to normalize the `ConvertedCompYearly` column.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ConvertedCompYearly  ConvertedCompYearly_Scaled\n",
      "0              65000.0                    0.003998\n",
      "1              65000.0                    0.003998\n",
      "2              65000.0                    0.003998\n",
      "3              65000.0                    0.003998\n",
      "4              65000.0                    0.003998\n"
     ]
    }
   ],
   "source": [
    "# --- Apply Min-Max Scaling manually using pandas ---\n",
    "min_val = df[\"ConvertedCompYearly\"].min()\n",
    "max_val = df[\"ConvertedCompYearly\"].max()\n",
    "\n",
    "df[\"ConvertedCompYearly_Scaled\"] = (df[\"ConvertedCompYearly\"] - min_val) / (max_val - min_val)\n",
    "\n",
    "print(df[[\"ConvertedCompYearly\", \"ConvertedCompYearly_Scaled\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>6.2 Log-transform the ConvertedCompYearly column to reduce skewness.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ConvertedCompYearly  ConvertedCompYearly_Log\n",
      "0              65000.0                11.082143\n",
      "1              65000.0                11.082143\n",
      "2              65000.0                11.082143\n",
      "3              65000.0                11.082143\n",
      "4              65000.0                11.082143\n"
     ]
    }
   ],
   "source": [
    "# --- Handle missing or non-positive values first ---\n",
    "df = df.copy()\n",
    "df[\"ConvertedCompYearly\"] = pd.to_numeric(df[\"ConvertedCompYearly\"], errors=\"coerce\")\n",
    "\n",
    "# Drop or replace non-positive values (since log cannot handle 0 or negative)\n",
    "df = df[df[\"ConvertedCompYearly\"] > 0]\n",
    "\n",
    "# --- Apply log transformation ---\n",
    "df[\"ConvertedCompYearly_Log\"] = np.log(df[\"ConvertedCompYearly\"])\n",
    "\n",
    "# --- Display before/after comparison ---\n",
    "print(df[[\"ConvertedCompYearly\", \"ConvertedCompYearly_Log\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>7.1 Create a new column `ExperienceLevel` based on the `YearsCodePro` column:</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   YearsCodePro ExperienceLevel\n",
      "0           2.0        Beginner\n",
      "1          17.0          Expert\n",
      "2          27.0          Expert\n",
      "3           2.0        Beginner\n",
      "4           2.0        Beginner\n",
      "5           2.0        Beginner\n",
      "6           7.0     Experienced\n",
      "7           2.0        Beginner\n",
      "8           2.0        Beginner\n",
      "9          11.0          Expert\n"
     ]
    }
   ],
   "source": [
    "# Ensure YearsCodePro is numeric (handles strings like \"Less than 1 year\")\n",
    "df[\"YearsCodePro\"] = pd.to_numeric(df[\"YearsCodePro\"], errors=\"coerce\")\n",
    "\n",
    "# --- Create ExperienceLevel column based on numeric ranges ---\n",
    "df[\"ExperienceLevel\"] = pd.cut(\n",
    "    df[\"YearsCodePro\"],\n",
    "    bins=[-np.inf, 2, 5, 10, np.inf],   # define boundaries\n",
    "    labels=[\"Beginner\", \"Intermediate\", \"Experienced\", \"Expert\"]\n",
    ")\n",
    "\n",
    "print(df[[\"YearsCodePro\", \"ExperienceLevel\"]].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you:\n",
    "\n",
    "- Explored the dataset to identify inconsistencies and missing values.\n",
    "\n",
    "- Encoded categorical variables for analysis.\n",
    "\n",
    "- Handled missing values using imputation techniques.\n",
    "\n",
    "- Normalized and transformed numerical data to prepare it for analysis.\n",
    "\n",
    "- Engineered a new feature to enhance data interpretation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "1e8e234f19fd098e27b0518a87f18de690e1c51f1d3263d5690927d19971251e"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
